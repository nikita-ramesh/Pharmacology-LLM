{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LLMs to Explore the IUPHAR Guide to Pharmacology\n",
    "Experiment with LLMs for the IUPHAR/BPS Guide to Pharmacology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import base64\n",
    "import logging\n",
    "import codecs\n",
    "import getpass\n",
    "import os\n",
    "import requests\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlglot\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To log any errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"query_errors.log\", level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**db_config)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Password generation function\n",
    "def pwd():\n",
    "    return getpass.getpass(prompt=\"Enter the database password: \")\n",
    "\n",
    "\n",
    "# Database connection details\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'guide_to_pharmacology',\n",
    "    'user': 'postgres',\n",
    "    'password': pwd(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully.\n"
     ]
    }
   ],
   "source": [
    "conn = connect_to_db()\n",
    "if conn:\n",
    "    print(\"Connected to the database successfully.\")\n",
    "else:\n",
    "    print(\"Failed to connect to the database. Please check your credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Train LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert the training set into OpenAI's prompt-completion format\n",
    "def convert_to_openai_format(df):\n",
    "    openai_format_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Format each row as a prompt-completion pair\n",
    "        openai_format_data.append({\n",
    "            \"prompt\": f\"{row['question']}\",\n",
    "            \"completion\": row['sql_query']\n",
    "        })\n",
    "    return openai_format_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalise SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_query(query):\n",
    "    try:\n",
    "        parsed_query = sqlglot.parse_one(query).sql()\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing query: {e}\")\n",
    "        return query  \n",
    "    return parsed_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Integrate LLM and SQL training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ask a question and get SQL using OpenAI API\n",
    "def ask_openai(question, train_df=None):\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    # If a training set is provided, convert it to the OpenAI format and append it to the system prompt\n",
    "    if train_df is not None:\n",
    "        training_data = convert_to_openai_format(train_df)\n",
    "        examples = \"\\n\".join([f\"Q: {item['prompt']} A: {item['completion']}\" for item in training_data])\n",
    "    else:\n",
    "        examples = \"\"\n",
    "    \n",
    "    # Constructing the data payload for OpenAI API with additional examples from the training data\n",
    "    data = {\n",
    "        \"model\": \"gpt-4o\",  # Or use your fine-tuned model if available\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": f'''\n",
    "                I have a database with the following schema:\n",
    "                Table: ‘object’ with columns: (abbreviation, only_grac, in_cgtp, annotation_status,\n",
    "                comments, object_id, only_iuphar, cite_id, systematic_name, gtip_comment, name,\n",
    "                gtmp_comment, in_gtip, old_object_id, in_gtmp, grac_comments, last_modified,\n",
    "                no_contributor_list, structural_info_comments, quaternary_structure_comments).\n",
    "                \n",
    "                Table: ‘ligand’ with columns: (old_ligand_id, has_chembl_interaction,\n",
    "                name_vector, mechanism_of_action_vector, comments, immuno_comments, antibacterial,\n",
    "                ligand_id, bioactivity_comments, absorption_distribution_vector, pubchem_sid,\n",
    "                metabolism_vector, comments_vector, popn_pharmacokinetics, bioactivity_comments_vector, elimination, drugs_url, abbreviation,\n",
    "                absorption_distribution, organ_function_impairment, emc_url, verified, mechanism_of_action, approved_source, who_essential, abbreviation_vector,\n",
    "                in_gtmp, metabolism, type, elimination_vector, approved, in_gtip, labelled, withdrawn_drug,\n",
    "                name, immuno_comments_vector, popn_pharmacokinetics_vector, ema_url, iupac_name,\n",
    "                clinical_use_vector, gtmp_comments, radioactive, has_qi_interaction,\n",
    "                gtmp_comments_vector, organ_function_impairment_vector, clinical_use).\n",
    "                \n",
    "                Table: ‘interaction’ with columns: (affinity_high, affinity_low, concentration_range,\n",
    "                original_affinity_relation, action_comment, assay_conditions, object_id,\n",
    "                original_affinity_units, endogenous, type_vector, original_affinity_high_nm,\n",
    "                action, affinity_median, voltage_dependent, assay_description, hide,\n",
    "                from_grac, whole_organism_assay, only_grac, original_affinity_low_nm,\n",
    "                percent_activity, affinity_units, affinity_voltage_median, primary_target, selectivity,\n",
    "                use_dependent, species_id, selective, ligand_id, target_ligand_id, ligand_context,\n",
    "                affinity_voltage_high, receptor_site, affinity_voltage_low, assay_url,\n",
    "                original_affinity_median_nm, interaction_id, rank, affinity_physiological_voltage, type.\n",
    "\n",
    "                Much more tables like this exist in the database.\n",
    "                \n",
    "                Here are some examples of how to translate natural language queries into SQL queries:\n",
    "                {examples}\n",
    "\n",
    "                If it is an essay type of query find relevant tables and topics from the database and generate appropriate SQL queries still.\n",
    "                Please write an SQL query based on the following natural language text:\n",
    "            '''},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Send the request to OpenAI API\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            message_content = response.json()['choices'][0]['message']['content']\n",
    "            if '```sql' in message_content:\n",
    "                sql_query = message_content.split('```sql')[1].split('```')[0].strip()\n",
    "                # sql_query = \" \".join(sql_query.lower().split())\n",
    "                sql_query = normalize_query(sql_query)\n",
    "                return sql_query\n",
    "            else:\n",
    "                print(\"No SQL query found in the response. Full response:\")\n",
    "                print(message_content)\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting SQL query: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to execute query and return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a query and return results\n",
    "def execute_query(conn, sql_query):\n",
    "    \"\"\" Executes a SQL query and returns the result as a DataFrame. \"\"\"\n",
    "    try:\n",
    "        return pd.read_sql_query(sql_query, conn)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error executing SQL query: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset\n",
    "def split_dataset(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    difficulty_cols = [\"Difficulty: Easy\", \"Difficulty: Easy-Moderate\", \"Difficulty: Moderate-Hard\", \"Difficulty: Hard\"]\n",
    "    df[\"Difficulty\"] = df[difficulty_cols].idxmax(axis=1).str.replace(\"Difficulty: \", \"\")\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"Difficulty\"], random_state=42)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Training/all_queries_categorised_train.csv\"  # Path to your dataset\n",
    "train_df, test_df = split_dataset(file_path)\n",
    "print(\"Dataset split into training and testing sets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Query Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the query results\n",
    "def evaluate_query(expected_df, result_df):\n",
    "    \"\"\"Evaluates the generated SQL query against the expected result.\"\"\"\n",
    "    \n",
    "    # Get columns that exist in both DataFrames\n",
    "    common_columns = list(set(expected_df.columns).intersection(result_df.columns))\n",
    "    \n",
    "    # Calculate missed and extra columns\n",
    "    missed_columns = len(set(expected_df.columns) - set(result_df.columns))\n",
    "    extra_columns = len(set(result_df.columns) - set(expected_df.columns))\n",
    "    \n",
    "    # Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
    "    if common_columns:\n",
    "        matches = (expected_df[common_columns] == result_df[common_columns])\n",
    "        true_positives = matches.sum().sum()  # Total number of matching elements\n",
    "        total_elements_in_result = result_df[common_columns].size  # Total elements in result DataFrame\n",
    "        total_elements_in_expected = expected_df[common_columns].size  # Total elements in expected DataFrame\n",
    "        \n",
    "        # Precision: Proportion of correct results out of all retrieved results\n",
    "        precision = true_positives / total_elements_in_result\n",
    "        \n",
    "        # Recall: Proportion of correct results out of all expected results\n",
    "        recall = true_positives / total_elements_in_expected\n",
    "    else:\n",
    "        precision = 0  # No common columns, precision is undefined (set to 0)\n",
    "        recall = 0     # No common columns, recall is undefined (set to 0)\n",
    "    \n",
    "    # Accuracy: Check if DataFrames are identical in content and structure\n",
    "    accuracy = expected_df.equals(result_df)\n",
    "    \n",
    "    # Calculate row-wise match count for common columns\n",
    "    if common_columns:\n",
    "        matched_rows = (expected_df[common_columns] == result_df[common_columns]).all(axis=1).sum()\n",
    "    else:\n",
    "        matched_rows = 0  # No rows can match if there are no common columns\n",
    "    \n",
    "    total_rows = len(expected_df)\n",
    "    \n",
    "    return {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Missed Columns\": missed_columns,\n",
    "        \"Extra Columns\": extra_columns,\n",
    "        \"Matched Rows\": matched_rows,\n",
    "        \"Total Rows\": total_rows\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Evaluating the test dataset...\")\n",
    "# test_metrics = evaluate_dataset(test_df, conn)\n",
    "# print(\"Evaluation results:\")\n",
    "# print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate SQL for test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_queries_for_test_df(test_df):\n",
    "    generated_queries = []\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        nl_query = row['Natural Language Query']  # Natural language query\n",
    "        # Generate SQL from OpenAI\n",
    "        generated_sql = ask_openai(nl_query)\n",
    "        \n",
    "        # Add generated SQL to the row for later comparison\n",
    "        row['Generated SQL'] = generated_sql\n",
    "        generated_queries.append(row)\n",
    "    \n",
    "    return pd.DataFrame(generated_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sql_queries(test_df):\n",
    "    results = []\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        expected_sql = row['SQL']\n",
    "        generated_sql = row['Generated SQL']\n",
    "        \n",
    "        # Compare exact match\n",
    "        match = expected_sql == generated_sql\n",
    "        \n",
    "        results.append({\n",
    "            \"ID\": row[\"ID\"],\n",
    "            \"Natural Language Query\": row[\"Natural Language Query\"],\n",
    "            \"Expected SQL\": expected_sql,\n",
    "            \"Generated SQL\": generated_sql,\n",
    "            \"Match\": match\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sql_queries(test_df, conn):\n",
    "    metrics = []\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        sql_query = row[\"SQL\"]\n",
    "        # second_sql = row.get(\"2nd SQL\")\n",
    "        \n",
    "        # Attempt to execute the main SQL query\n",
    "        expected_df = execute_query(conn, sql_query)\n",
    "        result_df = execute_query(conn, sql_query)\n",
    "\n",
    "        # If either query failed, log and continue\n",
    "        if expected_df is None or result_df is None:\n",
    "            logging.error(f\"Failed to execute main query for Query ID {row['ID']}: {sql_query}\")\n",
    "            continue\n",
    "\n",
    "        # Evaluate the main query\n",
    "        main_eval = evaluate_query(expected_df, result_df)\n",
    "\n",
    "        # if second_sql and pd.notnull(second_sql):\n",
    "        #     # Attempt to execute the second SQL query\n",
    "        #     second_expected_df = execute_query(conn, second_sql)\n",
    "        #     if second_expected_df is None:\n",
    "        #         logging.error(f\"Failed to execute second query for Query ID {row['ID']}: {second_sql}\")\n",
    "        #         second_eval = {key: 0 for key in main_eval.keys()}  # Default to 0 for all metrics\n",
    "        #     else:\n",
    "        #         second_eval = evaluate_query(second_expected_df, result_df)\n",
    "            \n",
    "        #     # Combine evaluations (use max values for each metric)\n",
    "        #     for key in main_eval:\n",
    "        #         main_eval[key] = max(main_eval[key], second_eval[key])\n",
    "\n",
    "        # Append results to metrics list\n",
    "        metrics.append({\n",
    "            \"Query ID\": row[\"ID\"],\n",
    "            \"Precision\": main_eval[\"Precision\"],\n",
    "            \"Recall\": main_eval[\"Recall\"],\n",
    "            \"Accuracy\": main_eval[\"Accuracy\"],\n",
    "            \"Missed Columns\": main_eval[\"Missed Columns\"],\n",
    "            \"Extra Columns\": main_eval[\"Extra Columns\"],\n",
    "            \"Matched Rows\": main_eval[\"Matched Rows\"],\n",
    "            \"Total Rows\": main_eval[\"Total Rows\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `conn` is your active database connection and `test_df` is your test DataFrame.\n",
    "# metrics_df = evaluate_sql_queries(test_df, conn)\n",
    "# print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_evaluation(file_path, conn):\n",
    "    # Step 1: Load and split the dataset\n",
    "    train_df, test_df = split_dataset(file_path)\n",
    "\n",
    "    # Step 2: Generate SQL queries for the test set\n",
    "    generated_test_df = generate_sql_queries_for_test_df(test_df)\n",
    "\n",
    "    # Step 3: Compare generated SQL with expected SQL\n",
    "    comparison_df = compare_sql_queries(generated_test_df)\n",
    "    print(\"Comparison of generated and expected SQL queries on the test set:\")\n",
    "    print(comparison_df)\n",
    "\n",
    "    # Step 4: Evaluate SQL queries on the database (for the test set)\n",
    "    evaluation_results = evaluate_sql_queries(generated_test_df, conn)\n",
    "    \n",
    "    # Step 5: Print the evaluation results in a detailed table format\n",
    "    print(\"Detailed Evaluation Results on the test set:\")\n",
    "    print(evaluation_results)\n",
    "\n",
    "    # Optionally, save the results to a file for further analysis\n",
    "    evaluation_results.to_csv('evaluation_results.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 502 - <html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Comparison of generated and expected SQL queries on the test set:\n",
      "    ID                             Natural Language Query  \\\n",
      "0   35  What antagonists are there for Toll-like recep...   \n",
      "1    6  Find synthetic organic ligands with a molecula...   \n",
      "2   81  Are there compounds which can block all adenos...   \n",
      "3   58  Find information on the clinical use of drugs ...   \n",
      "4    7  What information is there on Retinoic acid rec...   \n",
      "5   56  Find any endogenous substrates of decarboxylases?   \n",
      "6    4                            Find all approved drugs   \n",
      "7   15  What drugs might be used to treat multiple scl...   \n",
      "8   19  In humans, how many relaxin receptors are ther...   \n",
      "9   31  What antimalarial compounds also have a PDB st...   \n",
      "10  38  How many antibodies with binding data are ther...   \n",
      "11  53  Find any nucleic acid ligands and their sequen...   \n",
      "12  42  List ligands for SARS Cov2 MPro that have pAct...   \n",
      "13  65  Is there recommended background reading on end...   \n",
      "14  61  Are there any compounds that only target one m...   \n",
      "15   9  Search / find any ligand with the name contain...   \n",
      "16  70  Is IFN-β an agonoist of  interferon α/β recept...   \n",
      "17  77  Can I get a list of all ligands in GtoPdb with...   \n",
      "18  26  What should I use to inhibit TRPM3 in cultured...   \n",
      "19  18  Find apelin ligands that are radiolabelled tog...   \n",
      "20  69  What ligands and structures have a pKi values ...   \n",
      "21  40  Find natural products ligands, that meet lipin...   \n",
      "22  29  What compounds have a role in treating arthritis?   \n",
      "23  23  Find all the papers in the Guide that are list...   \n",
      "24  16  What WHO essential medicines, that are approve...   \n",
      "25  25      Which GPCRs have no clinically approved drug?   \n",
      "\n",
      "                                         Expected SQL  \\\n",
      "0   select l.ligand_id, l.name, l.type, o.object_i...   \n",
      "1   select l.ligand_id, l.name, l.type, lp.molecul...   \n",
      "2   select i.ligand_id, l.name, count(distinct i.o...   \n",
      "3   select distinct l.ligand_id, l.name, l.type, l...   \n",
      "4   select l.ligand_id, l.name, l.type, l.\"comment...   \n",
      "5   select l.ligand_id, l.name, l.type, o.object_i...   \n",
      "6   select ligand_id, name from ligand where appro...   \n",
      "7   select idl.ligand_id, l.name, idl.comment, d.n...   \n",
      "8   select o.object_id, o.name, dl.placeholder, co...   \n",
      "9   select l.ligand_id, l.name, l.gtmp_comments, l...   \n",
      "10  select count(distinct l.ligand_id) from intera...   \n",
      "11  select l.ligand_id, l.name, l.type, na.seq fro...   \n",
      "12  select l.ligand_id, l.name, l.type, o.object_i...   \n",
      "13  select r.reference_id, r.title, r.article_titl...   \n",
      "14  select i.ligand_id, l.name, count(distinct i.o...   \n",
      "15  select l.ligand_id, l.name, ls.synonym from li...   \n",
      "16  select count(*) from interaction i where i.lig...   \n",
      "17  select l.ligand_id, l.name, l.pubchem_sid, ldl...   \n",
      "18  select l.ligand_id, l.name, case when i.affini...   \n",
      "19  select l.ligand_id, l.name, l.radioactive, cas...   \n",
      "20  select l.ligand_id, l.name, l.type, ls.isomeri...   \n",
      "21  select l.ligand_id, l.name, l.type, ls.isomeri...   \n",
      "22  select idl.ligand_id, l.name, idl.comment, d.n...   \n",
      "23  select * from reference where pub_status ilike...   \n",
      "24  select ligand_id, name from ligand where who_e...   \n",
      "25  select i.object_id, (select name from object o...   \n",
      "\n",
      "                                        Generated SQL  Match  \n",
      "0   SELECT o.name AS receptor_name, l.name AS liga...  False  \n",
      "1   SELECT ligand_id, name FROM ligand WHERE type ...  False  \n",
      "2   SELECT DISTINCT l.name AS compound_name FROM l...  False  \n",
      "3   SELECT l.ligand_id, l.name AS ligand_name, l.c...  False  \n",
      "4   SELECT o.object_id, o.name AS receptor_name, i...  False  \n",
      "5   SELECT i.interaction_id, i.ligand_id, i.object...  False  \n",
      "6             SELECT * FROM ligand WHERE approved = 1  False  \n",
      "7   SELECT DISTINCT l.name FROM ligand AS l WHERE ...  False  \n",
      "8   SELECT o.name AS receptor_name, i.action AS pr...  False  \n",
      "9   SELECT c.* FROM compounds AS c JOIN pdb_struct...  False  \n",
      "10  SELECT COUNT(DISTINCT l.ligand_id) AS antibody...  False  \n",
      "11  SELECT ligand_id, name, type, sequence FROM li...  False  \n",
      "12  SELECT l.name, l.ligand_id FROM interaction AS...  False  \n",
      "13  SELECT abbreviation, name, systematic_name, co...  False  \n",
      "14  SELECT DISTINCT l.name AS ligand_name FROM lig...  False  \n",
      "15       SELECT * FROM ligand WHERE name LIKE '%GSK%'  False  \n",
      "16                                               None  False  \n",
      "17  SELECT name AS ligand_name, pubchem_sid, pubch...  False  \n",
      "18  SELECT i.ligand_id, l.name AS ligand_name, i.c...  False  \n",
      "19  SELECT l.name AS ligand_name, i.affinity_media...  False  \n",
      "20  SELECT l.ligand_id, l.name AS ligand_name, o.o...  False  \n",
      "21  SELECT l.ligand_id, l.name, l.iupac_name, l.ty...  False  \n",
      "22  SELECT ligand_id, name, clinical_use, mechanis...  False  \n",
      "23     SELECT * FROM papers WHERE status = 'preprint'  False  \n",
      "24  SELECT * FROM ligand WHERE who_essential = TRU...  False  \n",
      "25  SELECT DISTINCT o.name AS gpcr_name FROM objec...  False  \n",
      "Detailed Evaluation Results on the test set:\n",
      "    Query ID  Precision  Recall  Accuracy  Missed Columns  Extra Columns  \\\n",
      "0         35          0       0      True               0              0   \n",
      "1          6          0       0      True               0              0   \n",
      "2         81          0       0      True               0              0   \n",
      "3         58          0       0      True               0              0   \n",
      "4          7          0       0      True               0              0   \n",
      "5         56          0       0      True               0              0   \n",
      "6          4          0       0      True               0              0   \n",
      "7         15          0       0      True               0              0   \n",
      "8         19          0       0      True               0              0   \n",
      "9         31          0       0      True               0              0   \n",
      "10        38          0       0      True               0              0   \n",
      "11        53          0       0      True               0              0   \n",
      "12        42          0       0      True               0              0   \n",
      "13        65          0       0      True               0              0   \n",
      "14        61          0       0      True               0              0   \n",
      "15         9          0       0      True               0              0   \n",
      "16        70          0       0      True               0              0   \n",
      "17        77          0       0      True               0              0   \n",
      "18        26          0       0      True               0              0   \n",
      "19        18          0       0      True               0              0   \n",
      "20        69          0       0      True               0              0   \n",
      "21        40          0       0      True               0              0   \n",
      "22        29          0       0      True               0              0   \n",
      "23        23          0       0      True               0              0   \n",
      "24        16          0       0      True               0              0   \n",
      "25        25          0       0      True               0              0   \n",
      "\n",
      "    Matched Rows  Total Rows  \n",
      "0              0           0  \n",
      "1              0           0  \n",
      "2              0           0  \n",
      "3              0           0  \n",
      "4              0           0  \n",
      "5              0           0  \n",
      "6              0           0  \n",
      "7              0           0  \n",
      "8              0           0  \n",
      "9              0           0  \n",
      "10             0           0  \n",
      "11             0           0  \n",
      "12             0           0  \n",
      "13             0           0  \n",
      "14             0           0  \n",
      "15             0           0  \n",
      "16             0           0  \n",
      "17             0           0  \n",
      "18             0           0  \n",
      "19             0           0  \n",
      "20             0           0  \n",
      "21             0           0  \n",
      "22             0           0  \n",
      "23             0           0  \n",
      "24             0           0  \n",
      "25             0           0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Training/all_queries_categorised_train.csv\"\n",
    "run_full_evaluation(file_path, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run your Own Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     query = input(\"Enter an SQL query to execute (or type 'exit' to quit): \")\n",
    "#     if query.lower() == 'exit':\n",
    "#         break\n",
    "\n",
    "#     results = execute_query(conn, query)\n",
    "#     if results is not None and not results.empty:\n",
    "#         print(\"Query Results:\")\n",
    "#         print(results)\n",
    "#     else:\n",
    "#         print(\"No results found or an error occurred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close DB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "conn.close()\n",
    "print(\"Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
